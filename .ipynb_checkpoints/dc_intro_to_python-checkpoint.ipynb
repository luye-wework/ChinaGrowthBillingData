{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h1>Data Analysis in Python</h1>\n",
    "</p>\n",
    "<p>\n",
    "    So, we want to be able to fill in some of the blanks to be able to measure the impact of our problem statement. We know that we've defined the following formula to measure our impact:\n",
    "</p>\n",
    "<p>\n",
    "    <center><em>Total No-Shows   x   Cost Per Desk   x   Average Desks Reserved   x   Tour Conversion Rate</em></center>\n",
    "</p>\n",
    "<p>\n",
    "    We can use Python to compute all of these variables! But before we do that, we'll first review some of the techniques you'll need to be able to do these computations.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h2>Getting the Data</h2>\n",
    "</p>\n",
    "<p>\n",
    "    If we want to use data to answer these questions, we first need to <em>get</em> the data into our Python environment. There are a lot of ways to do this! One of the best is to connect straight to Redshift using Python. We'll do that using a tool called <strong>WeModule.</strong>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h3>WeModule</h3>\n",
    "</p>\n",
    "<p>\n",
    "    WeModule is a library that was built by the Data Engineering team at WeWork. It has a lot of functionality, but one of its most common uses is to create a connection to Redshift using one line of code, then being able to execute SQL queries and return the results right into Python. The following cells walk you through how to connect to Redshift and execute a query with WeModule.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Tips to move around faster in a Jupyter Notebook:\n",
    "</p>\n",
    "<p>\n",
    "    <ul>\n",
    "        <li>Execute the code in the cell you're typing in: Shift + Enter</li>\n",
    "        <li>Deselect a cell (turns the cursor blue, stops typing code in the cell): Escape</li>\n",
    "        <li>Type code into a cell while the cursor is blue: Enter</li>\n",
    "        <li>Move up and down from cell to cell: Escape (deselect), then Arrow Up/Down</li>\n",
    "        <li>Add a cell above the current cell: Escape (deselect), then <em>a</em></li>\n",
    "        <li>Add a cell below the current cell: Escape (deselect), then <em>b</em></li>\n",
    "    </ul>\n",
    "<p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# import relevant libraries\n",
    "import os\n",
    "from we_module.we import We"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our connection string and assign it to a variable:\n",
    "# ACTION: replace username and password with your username and password\n",
    "rs_conn = 'postgresql://username:password@redshift-production.weworkers.io:5439/analyticdb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign our connection to an environment variable (this is how WeModule connects to Redshift in the background)\n",
    "os.environ['REDSHIFT_CONN'] = rs_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:we_module.we:Connected to redshift\n",
      "INFO:we_module.we:SELECT nspname from pg_catalog.pg_namespace;\n",
      "INFO:we_module.we:read redshift connection reconnected because of 0 minutes of inactivity.\n"
     ]
    }
   ],
   "source": [
    "# now define our connection by instantiating the We Class and assigning it to a variable!\n",
    "we = We()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    This variable, <strong><em>we</em></strong>, represents your connection to Redshift through Python! It has a series of methods and attributes, or capabilities to do things that interact with Redshift based on the connection it made using your login credentials. <br> <br> To see available methods, type <em>we.</em> then hit tab in the cell below:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "we."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h4>The <em>we.get_tbl_query</em> Method</h4>\n",
    "</p>\n",
    "<p>\n",
    "    This method allows us to evaluate SQL queries and get the results returned to us in our Python environment. We simply pass a SQL query to it in the form of a string, then we execute the code and we get our data. Since we're interested in tours, we'll be querying the data from a view called <strong><em>mv_tour_details</em></strong> in the <strong><em>dw</em></strong> schema.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our sql query as a string variable\n",
    "tours_sql = '''\n",
    "SELECT\n",
    "    id\n",
    "    , salesforce_id\n",
    "    , tour_created_at::date as tour_created_at\n",
    "    , local_tour_date\n",
    "    , status\n",
    "FROM dw.mv_tour_details t\n",
    "where TRUE\n",
    "    AND tour_created_at::date between '2018-01-01' and '2018-12-31'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:we_module.we:\n",
      "SELECT\n",
      "    id\n",
      "    , salesforce_id\n",
      "    , tour_created_at::date as tour_created_at\n",
      "    , local_tour_date\n",
      "    , status\n",
      "FROM dw.mv_tour_details t\n",
      "where TRUE\n",
      "    AND tour_created_at::date between '2018-01-01' and '2018-12-31'\n",
      "\n",
      "INFO:we_module.we:read redshift connection reconnected because of 0 minutes of inactivity.\n"
     ]
    }
   ],
   "source": [
    "# pass our sql to the method as an argument, then assign the results of the method to another variable\n",
    "df = we.get_tbl_query(tours_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h2>DataFrames</h2>\n",
    "</p>\n",
    "<p>\n",
    "    Now we have our query results stored in this variable called <strong><em>df</em></strong>. But what exactly is this variable? It's a DataFrame! It's a tabular representation of data that you can manipulate with code. It's the most common way that analysts work with data in Python. DataFrames come from another library called <strong><em>pandas</em></strong>. We'll walk through some of the basic commands for exploring and manipulating datasets, then we'll come back to computing our variables to calculate our impact.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h3>Getting an Overview</h3>\n",
    "</p>\n",
    "<p>\n",
    "    There are some common methods that we'll explore to simply see what data we have in our DataFrame:\n",
    "    <ul>\n",
    "        <li>Counting the rows and columns</li>\n",
    "        <li>Looking at the data</li>\n",
    "        <li>Checking for null values</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to know the dimensions of our data - rows x columns (notice how .shape has no parentheses at the end!)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see the first few rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values - why might we want to do this?\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h3>Getting into the Details</h3>\n",
    "</p>\n",
    "<p>\n",
    "    Now we'll take a look at some mothods to explore the data in more detail:\n",
    "    <ul>\n",
    "        <li>Summarty stats of data</li>\n",
    "        <li>Unique values of data</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of data in columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for non-numeric columns - what are the different values we have?\n",
    "df.status.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h3>Manipulating the Data</h3>\n",
    "</p>\n",
    "<p>\n",
    "    Finally, we'll walk through some methods that allow us to analyze the data:\n",
    "    <ul>\n",
    "        <li>Filtering</li>\n",
    "        <li>Cleaning</li>\n",
    "        <li>Arithmetic</li>\n",
    "        <li>Transformations</li>\n",
    "        <li>Aggregating</li>\n",
    "        <li>Renaming Columns</li>\n",
    "        <li>Sorting</li>\n",
    "    </ul>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering is useful when we're only interested in a subset of our data\n",
    "df[df.status=='Completed'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning: working with nulls can make our lives difficult - let's drop the row where we don't have a local tour date\n",
    "df.dropna(subset=['local_tour_date'], inplace=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can aggregate to derive insights, like seeing the frequency of tours on any day of the year!\n",
    "df.groupby('local_tour_date').size().reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for formatting purposes, sometimes we want to rename columns so that they're more interpretable\n",
    "df.groupby('local_tour_date').size().reset_index().rename({0: 'cnt'}, axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if we wanted to know the 5 days with the most scheduled tours? we can add a sort method, too!\n",
    "df.groupby('local_tour_date').size().reset_index().rename(\n",
    "    {0: 'cnt'}, axis=1).sort_values('cnt', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h2>Apply it! Measuring the Impact of our Problem Statement</h2>\n",
    "</p>\n",
    "<p>\n",
    "    <center><em>Total No-Shows   x   Cost Per Desk   x   Average Desks Reserved   x   Tour Conversion Rate</em></center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Now, let's actually use data to calculate some of these variables. Given that we have tour booking and results data already, let's try computing <strong><em>Total No-Shows</em></strong>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it yourself!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h3>Calculating the Impact</h3>\n",
    "</p>\n",
    "<p>\n",
    "    So, now that we know how many Total No-Shows there were in 2018, using that, plus the assumptions we'll make around the other variables, let's calculate the impact!\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_show_count = \n",
    "cost_per_desk_assumed = 600\n",
    "avg_desks_booked_assumed = 3\n",
    "tour_conversion_rate_assumed = .15\n",
    "print(no_show_count * cost_per_desk_assumed * avg_desks_booked_assumed * tour_conversion_rate_assumed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h2>Apply It! Advanced</h2>\n",
    "</p>\n",
    "<p>\n",
    "    Obviously making assumptions is okay! But if we want to try to be more accurate in our estimated impact, we can always use data to define the other variables in our impact formula. This section gives you the SQL to get the data needed to compute some of the other variables in our impact, then leaves you to use the techniques we've covered today to arrive at your own answers.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Let's try it again with a different dataset - this time for reservations. We'll give you the SQL, but now you guys use the code we've reviewed to repurpose it to do the same analysis for <strong><em>Average Desks Reserved</em></strong>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reservation_sql = '''\n",
    "SELECT\n",
    "    account_uuid\n",
    "    , reservable_type\n",
    "    , reservation_price\n",
    "    , CAST(real_capacity as float)\n",
    "from dw.mv_fact_reservable_reservation r\n",
    "left join dw.mv_dim_location l\n",
    "    on r.location_uuid = l.location_uuid\n",
    "where true\n",
    "    and date_sold_est between '2018-01-01' and '2018-12-31'\n",
    "    and l.country = 'United States'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:we_module.we:\n",
      "SELECT\n",
      "    account_uuid\n",
      "    , reservable_type\n",
      "    , reservation_price\n",
      "    , CAST(real_capacity as float)\n",
      "from dw.mv_fact_reservable_reservation r\n",
      "left join dw.mv_dim_location l\n",
      "    on r.location_uuid = l.location_uuid\n",
      "where true\n",
      "    and date_sold_est between '2018-01-01' and '2018-12-31'\n",
      "    and l.country = 'United States'\n",
      "\n",
      "INFO:we_module.we:read redshift connection reconnected because of 0 minutes of inactivity.\n"
     ]
    }
   ],
   "source": [
    "# try it yourself!\n",
    "res_df = we.get_tbl_query(reservation_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    Using the same dataset we just analyzed for <em>Average Desks Reserved</em>, let's do the same analysis to get a data-driven figure for <strong><em>Cost Per Desk</strong></em>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try it yourself!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <strong><em>Advanced:</em></strong> Now let's try a more difficult calculation - <strong><em>Tour Conversion Rate</em></strong>. Again, we'll give you the SQL, but it will take some extra steps to manipulate the data to get the metric that we want. <br><br>(Hint: you've still learned all the necessary techniques in this tutorial!)<br><br>(Another Hint: What's your definition of <em>Tour Conversion Rate</em>?)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_sql = '''\n",
    "with ct as (\n",
    "select id, salesforce_id, company_uuid, tour_created_at::date as tour_created_at, local_tour_date, status\n",
    "from dw.mv_tour_details\n",
    "where true\n",
    "    and status = 'Completed'\n",
    "    and tour_created_at::date between '2018-01-01' and '2018-12-31'\n",
    ")\n",
    ", reservations as (\n",
    "select distinct account_uuid\n",
    "from dw.mv_fact_reservable_reservation \n",
    ")\n",
    "select\n",
    "    ct.id\n",
    "    , ct.tour_created_at\n",
    "    , ct.local_tour_date\n",
    "    , ct.status\n",
    "    , case when r.account_uuid is not null then TRUE else FALSE end as converted\n",
    "from ct\n",
    "left join reservations r\n",
    "    on ct.company_uuid = r.account_uuid\n",
    ";\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:we_module.we:\n",
      "with ct as (\n",
      "select id, salesforce_id, company_uuid, tour_created_at::date as tour_created_at, local_tour_date, status\n",
      "from dw.mv_tour_details\n",
      "where true\n",
      "    and status = 'Completed'\n",
      "    and tour_created_at::date between '2018-01-01' and '2018-12-31'\n",
      ")\n",
      ", reservations as (\n",
      "select distinct account_uuid\n",
      "from dw.mv_fact_reservable_reservation \n",
      ")\n",
      "select\n",
      "    ct.id\n",
      "    , ct.tour_created_at\n",
      "    , ct.local_tour_date\n",
      "    , ct.status\n",
      "    , case when r.account_uuid is not null then TRUE else FALSE end as converted\n",
      "from ct\n",
      "left join reservations r\n",
      "    on ct.company_uuid = r.account_uuid\n",
      ";\n",
      "\n",
      "INFO:we_module.we:read redshift connection reconnected because of 0 minutes of inactivity.\n"
     ]
    }
   ],
   "source": [
    "# try it yourself!\n",
    "conv_df = we.get_tbl_query(conversion_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Appendix</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><h2>Advanced Topics: Brainstorming Solutions by Finding Insights</h2></p>\n",
    "<p>\n",
    "    Our problem statement is in pretty good shape now! However, the problem statement addresses the total scope of the problem for <em>all</em> no-shows. Since this is a good problem statement, there are <em>many</em> potential solutions we can deploy. But how do we identify those solutions? We can start by asking ourselves:\n",
    "</p>\n",
    "<p>\n",
    "    <center><em>What factors have an impact on whether a tour booking results in a no-show?</em></center>\n",
    "</p>\n",
    "<p>\n",
    "    We call identifying factors that appear to have a relationship with tour outcome <em>finding insights</em>. We can use these insights to inform our brainstorming sessions about the solution we ultimately build.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <h3>Insight 1: No-Show by Days Booked Before Tour</h3>\n",
    "</p>\n",
    "<p>\n",
    "    Let's hypothesize: do we think that there is a relationship between how far in advance a user books a tour and whether or not that tour results in a no-show? Let's find out!\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more advanced: we can define new metrics to analyze that are based on computations of existing fields\n",
    "\n",
    "# we'll do this by defining a custom function and then applying it do the dataframe\n",
    "def get_days_difference(early_date, later_date):\n",
    "    delta = later_date - early_date\n",
    "    return delta.days\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df['book_days_before_tour'] = df.apply(\n",
    "    lambda x: get_days_difference(x['tour_created_at'], x['local_tour_date']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's take a look at the number of no-shows that occur by the number of days before the tour was booked\n",
    "days_before_tour_no_shows = df[df.status=='No Show'].groupby(\n",
    "    'book_days_before_tour').size().reset_index().rename({0: 'cnt'}, axis=1)\n",
    "# subset to 0-15 days before\n",
    "days_before_tour_no_shows[days_before_tour_no_shows.book_days_before_tour.between(0,15)].sort_values(\n",
    "    'book_days_before_tour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# easier to consume the data as a chart!\n",
    "# subset to 0-15 days before\n",
    "dbtns_sorted = days_before_tour_no_shows[days_before_tour_no_shows.book_days_before_tour.between(0,15)].sort_values(\n",
    "    'book_days_before_tour')\n",
    "plt.bar(dbtns_sorted.book_days_before_tour, dbtns_sorted.cnt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><h3>Okay! It looks like the bulk of our no-shows occur for tours that are booked 0-1 days before the tour is scheduled. But let's think about this insight a bit deeper - what's the problem with using raw counts of no-shows?</h3></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the issue with using raw counts of no-shows? the data isn't normalized!\n",
    "# normalized data typically comes in the form of a ratio: \n",
    "# in this example, the most no-shows may occur 0-1 days before scheduled tour because the most tours\n",
    "# get booked 0-1 days before, but it might be relatively few no-shows in the picture of all tours booked 0-1\n",
    "# days before\n",
    "# let's normalize our data to get no-show rate: total no-shows divided by total tours\n",
    "\n",
    "# get a ratio of no-shows to total tours by days booked before, we first need total tours by days booked before\n",
    "total_tours = df[df.status.isin(['No Show','Completed'])].groupby(\n",
    "    'book_days_before_tour').size().reset_index().rename({0: 'ttl'}, axis=1)\n",
    "total_tours.sort_values('book_days_before_tour', inplace=True)\n",
    "# subset to 0-15 days before\n",
    "total_tours_sub = total_tours[total_tours.book_days_before_tour.between(0,15)]\n",
    "total_tours_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have both no-show count and total tour count, we can join the data and compute no-show rate\n",
    "no_show_rates = dbtns_sorted.merge(total_tours_sub, how='left', on='book_days_before_tour')\n",
    "no_show_rates['no_show_rate'] = no_show_rates.cnt/no_show_rates.ttl\n",
    "no_show_rates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# now let's visualize!\n",
    "plt.plot(no_show_rates.book_days_before_tour, no_show_rates.no_show_rate)\n",
    "plt.ylim([0,.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><h3>Whoa, no-show rate skyrockets when tours are booked further in advance! Now we can brainstorm: what kinds of solutions can we build to incentivize our PNMs to book their tours as close to the actual tour date as possible?</h3></p>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
